FROM python:3.11-slim

# Install system dependencies (git needed for torch.hub clone, build tools for praat-parselmouth)
RUN apt-get update && apt-get install -y \
    git \
    build-essential \
    cmake \
    ninja-build \
    && rm -rf /var/lib/apt/lists/*

# Install uv
COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/local/bin/uv

# Set working directory
WORKDIR /app

# Copy dependency files and application code (needed for editable install)
COPY pyproject.toml README.md ./
COPY src/ ./src/
COPY app/ ./app/
COPY scripts/ ./scripts/

# Install dependencies (include qualitative-voice extras for evaluation metrics)
RUN uv pip install --system -e ".[qualitative-voice]"

# ============================================================
# Pre-download qualitative metric models into the image so
# they are available immediately and not fetched at runtime.
# ============================================================

# 1. UTMOS MOS predictor (torch.hub -> /root/.cache/torch/hub/)
RUN python -c "import torch; model = torch.hub.load('tarepan/SpeechMOS:v1.2.0', 'utmos22_strong', trust_repo=True); print('UTMOS MOS predictor cached successfully')"

# 2. Emotion classifier + Valence/Arousal model (HuggingFace -> /root/.cache/huggingface/hub/)
RUN python -c "from transformers import pipeline, AutoProcessor, AutoModelForAudioClassification; pipe = pipeline('audio-classification', model='ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition'); print('Emotion classifier cached successfully'); proc = AutoProcessor.from_pretrained('audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim'); mdl = AutoModelForAudioClassification.from_pretrained('audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim'); print('Valence/arousal model cached successfully')"

# Create uploads directory
RUN mkdir -p /app/uploads

# Run Celery worker
CMD ["celery", "-A", "app.workers.celery_app", "worker", "--loglevel=info"]

